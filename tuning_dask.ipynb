{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6c1c06-5af8-4092-be90-ab95b08f1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import os \n",
    "import time\n",
    "\n",
    "import dask\n",
    "from dask import delayed\n",
    "from dask.distributed import LocalCluster, SSHCluster, Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "import sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49d61e-ae97-4235-bf05-6b315ca05f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for MissForest (it is only compatible up to scikit-learn 1.1.3!!)\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "\n",
    "# needed for GAIN\\n\",\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from GAIN import gain\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebabd36-2e26-4883-9c9b-d882e004eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"output_dask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ee1b91-a90a-4b57-b453-5e71db681fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (different test train splits in one table)\n",
    "df_train = pd.read_csv(\"data/train_table_0.8_folds.csv\")\n",
    "df_test = pd.read_csv(\"data/test_table_0.8_folds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a03979c-5097-4f6e-85a6-7b074b7b5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define iterables\n",
    "algorithms = [\"mean_imputer\", \"knn_imputer\", \"missforest_imputer\", \"gain_imputer\"]\n",
    "iterations = range(50)\n",
    "missing_value_proportions = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 99] + [100 / len(df_train[df_train[\"fold\"]==0])]\n",
    "folds = df_train[\"fold\"].unique()\n",
    "\n",
    "# hyperparameter combinations to test\n",
    "test_dict = [{\"imputer_name\": \"knn_imputer\",\n",
    "              \"param_grid\": {\"n_neighbors\": [1, 5, 10, 20, 30, 40, 50], \"weights\": [\"uniform\", \"distance\"]}},\n",
    "             {\"imputer_name\": \"missforest_imputer\",\n",
    "              \"param_grid\": {\"n_estimators\": [10, 50, 100, 200], \"max_iter\": [30], \"decreasing\": [False],\n",
    "                             \"criterion\": [\"squared_error\"], \"max_features\": [None], \"random_state\": [0],\n",
    "                             \"missing_values\": [np.nan]}},\n",
    "             {\"imputer_name\": \"gain_imputer\",\n",
    "              \"param_grid\": {\"alpha\": [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300], \"batch_size\": [128],\n",
    "                             \"hint_rate\": [0.9, 0.5], \"iterations\": [10000]}},\n",
    "             {\"imputer_name\": \"iterative_ridge_imputer\",\n",
    "              \"param_grid\": {\"tol\": [1e-3], \"max_iter\": [100, 1000], \"sample_posterior\": [False],\n",
    "                             \"estimator\": [BayesianRidge()], \"random_state\": [0]}},\n",
    "             {\"imputer_name\": \"mean_imputer\",\n",
    "              \"param_grid\": {\"missing_values\": [np.nan], \"strategy\": ['mean']}},\n",
    "             {\"imputer_name\": \"iterative_rf_imputer\",\n",
    "              \"param_grid\": {\"estimator\":  [RandomForestRegressor(n_estimators=5),\n",
    "                                            RandomForestRegressor(n_estimators=10), \n",
    "                                            RandomForestRegressor(n_estimators=50),\n",
    "                                           RandomForestRegressor(n_estimators=100),\n",
    "                                           RandomForestRegressor(n_estimators=200)], \"max_iter\":[30, 50, 100], \"random_state\": [0]}}\n",
    "             ]\n",
    "\n",
    "grid_search_dict = {}\n",
    "for imputer_name in algorithms:\n",
    "    param_grid = [x for x in test_dict if x[\"imputer_name\"] == imputer_name][0][\"param_grid\"]\n",
    "    grid_search = [x for x in it.product(*param_grid.values())]\n",
    "    \n",
    "    temp_grid_search = []\n",
    "    for i in range(len(grid_search)):\n",
    "        temp = {}\n",
    "        for j in range(len(param_grid.keys())):\n",
    "            temp[list(param_grid.keys())[j]] = grid_search[i][j]\n",
    "        temp_grid_search.append(temp)\n",
    "\n",
    "    grid_search_dict[imputer_name] = temp_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68c8cd-54eb-4a9a-a8aa-e8a5654e2c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a868f68-6c81-45fd-b954-d2f20aa49f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565e6bd-cf46-4bc7-8daa-0908a0b9f20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c10b7726-860c-4285-b82d-42b7f6405ae4",
   "metadata": {},
   "source": [
    "# Set up dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e970f0d-6637-4a13-b3bf-34f8a5f2c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set(scheduler=\"distributed\")  # Set Dask scheduler to distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32bf2f-ec12-4893-b54a-2e512842e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one node \n",
    "# client = Client(n_workers=8, threads_per_worker=1)\n",
    "# client = Client(n_workers=1)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b66958-0d05-42a0-aab7-e635517e3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple nodes\n",
    "cluster = SLURMCluster(\n",
    "                queue='mpp', #-P\n",
    "                account=\"oekochem.oekochem\", #-A\n",
    "                cores=128,  # number of cores per node\n",
    "                processes=24, # 12,\n",
    "                walltime='12:00:00', #--time\n",
    "                memory='250GB',\n",
    "                interface='ib0',  # connection between nodes\n",
    "                local_directory=\"/tmp/\", \n",
    "                job_extra_directives=[\"--qos 12h\" ,\n",
    "                                      \"-o ./log/dask-worker-%j.log\",\n",
    "                                      \"-e ./log/dask-worker-%j.err\",\n",
    "                                      \"--verbose\",\n",
    "                                      \"--export=OMP_NUM_THREADS=1\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb32e5-b6c9-4eab-8567-728a1dc7e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=24)\n",
    "#cluster.adapt(maximum_jobs=20)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc37157-9ec6-4cef-a475-d60171adfd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue -u yvjennig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53678afe-dba7-4c62-a06b-7cc856fa81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe98771c-c215-484a-8cfa-3a4764c67fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e7916-fa54-42d3-9471-66f25cc9c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loops in one function\n",
    "# for loops outside function\n",
    "# merge all folds into one dataset\n",
    "# joblib\n",
    "# sciris\n",
    "# dask process bar\n",
    "\n",
    "# willy rath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc92823-d0bd-4f45-8ee7-9cb4d0982af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_imputer(x_in, y_in, predicting_in, hyperparamerter_dict_in, imputer_name_in):\n",
    "    if imputer_name_in == \"gain_imputer\":\n",
    "        s_impute_time = time.time()\n",
    "        x_hat = pd.DataFrame(gain.gain(x_in.to_numpy(), hyperparamerter_dict_in), columns=x_in.columns)\n",
    "        impute_time = time.time() - s_impute_time\n",
    "    else:\n",
    "        if imputer_name_in == \"knn_imputer\":\n",
    "            imputer = KNNImputer(**hyperparamerter_dict_in)\n",
    "        elif imputer_name_in == \"missforest_imputer\":\n",
    "            imputer = MissForest(**hyperparamerter_dict_in)\n",
    "        elif imputer_name_in == \"iterative_ridge_imputer\" or imputer_name_in == \"iterative_rf_imputer\":\n",
    "            imputer = IterativeImputer(**hyperparamerter_dict_in)\n",
    "        elif imputer_name_in == \"mean_imputer\":\n",
    "            imputer = SimpleImputer(**hyperparamerter_dict_in)\n",
    "            # x_hat = imputer.fit_transform(x_in)\n",
    "        else:\n",
    "            print(\"run_imputer: Unknown imputer!\")\n",
    "\n",
    "        s_impute_time = time.time()\n",
    "        x_hat = pd.DataFrame(imputer.fit_transform(x_in), columns=x_in.columns)  # @todo can we use pd or dd dataframes??\n",
    "        impute_time = time.time() - s_impute_time\n",
    "\n",
    "    # compute RMSE\n",
    "    rmse = np.linalg.norm(x_hat[predicting_in] - y_in[predicting_in]) / np.sqrt(len(y_in))\n",
    "\n",
    "    return rmse, impute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd5e45b-2bf7-4f76-a565-25d5776c663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_values_from_one_param_by_index_and_scale(x_in, parameter_in, indexes_in):\n",
    "    x = x_in.copy()\n",
    "    x.loc[indexes_in, parameter_in] = np.nan\n",
    "\n",
    "    # scale data\n",
    "    x_scaled, y_scaled = scale_data(x, x_in)\n",
    "    return x_scaled, y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaaa6103-f977-4b5c-9cb3-3488effee544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(x_in, y_in):\n",
    "    # NOT WORKING ON DASK DELAYED OBJECTS\n",
    "    # scale data\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler().fit(x_in)  # RobustScaler().fit(x_in) # StandardScaler().fit(x_in)\n",
    "    x_scaled = pd.DataFrame(scaler.transform(x_in), columns=x_in.columns)\n",
    "    y_scaled = pd.DataFrame(scaler.transform(y_in), columns=y_in.columns)\n",
    "    return x_scaled, y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6454ebc7-a4fc-45c2-ada8-be299bb06c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_values_globally_and_scale(x_in, proportion_in, parameters_in):\n",
    "    # randomly remove k% from all parameter columns (globally) (100% equals the LENGTH of x, not length*width\n",
    "    # to keep it comparable to the other run (where k% are removed from one column only)\n",
    "    x = x_in.copy()  # we do not want to change inputs directly\n",
    "    x_rows = x[parameters_in].shape[0]\n",
    "    x_cols = x[parameters_in].shape[1]\n",
    "\n",
    "    # number of values to set to nan\n",
    "    # round(len(x) * proportion_in / 100) \n",
    "    num_vals = round(len(x)*len(parameters_in)*proportion_in/100)\n",
    "\n",
    "    nan_mat = np.zeros(shape=(x_rows * x_cols,), dtype=bool)  # create array of False\n",
    "    nan_mat[:num_vals] = True  # set first num_vals elements to True\n",
    "    nan_mat = np.random.permutation(nan_mat)  # shuffle\n",
    "    nan_mat = np.reshape(nan_mat, (x_rows, x_cols))  # bring to right shape\n",
    "\n",
    "    # concat lat, lon, depth columns with parameter columns (only from latter value were removed)\n",
    "    x = pd.concat([x[[p for p in x.columns if p not in parameters_in]], x[parameters_in].mask(nan_mat)], axis=1)\n",
    "\n",
    "    # scale data\n",
    "    x_scaled, y_scaled = scale_data(x, x_in)\n",
    "    return x_scaled, y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a90540-4fdd-4878-b8d0-5921967bbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @delayed\n",
    "def experiment0(df_train, algorithm, fold, iteration, missingness, grid_search):\n",
    "    filename = f\"{output_dir}exp0_{algorithm}_{fold}_{iteration}_{missingness}.csv\"\n",
    "\n",
    "    res = []\n",
    "    if not os.path.isfile(filename):\n",
    "        df_train_temp = df_train[df_train[\"fold\"]==fold].drop(\"fold\", axis=1)\n",
    "        parameters = [x for x in df_train_temp.columns if x.startswith(\"P_\")]\n",
    "    \n",
    "        x0, y0 = drop_values_globally_and_scale(x_in=df_train_temp, proportion_in=missingness, parameters_in=parameters)\n",
    "    \n",
    "        for hyperparamerter_combination in grid_search:\n",
    "            rmse0, impute_time0 = run_imputer(x_in=x0, y_in=y0,\n",
    "                                              predicting_in=parameters,\n",
    "                                              hyperparamerter_dict_in=hyperparamerter_combination,\n",
    "                                              imputer_name_in=algorithm)\n",
    "            res.append(pd.DataFrame({\"iteration\": [iteration],\n",
    "                                     \"missing_value_proportion\": [missingness],\n",
    "                                     \"predicting\": [str(parameters)],\n",
    "                                     \"imputer\": [algorithm],\n",
    "                                     \"time\": [impute_time0],\n",
    "                                     \"rmse\": [rmse0],\n",
    "                                     \"hyperparameters\": [hyperparamerter_combination],\n",
    "                                     \"fold\": [fold]}))\n",
    "        pd.concat(res).to_csv(filename, index=False)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd21c72-af04-4f12-80a8-a80b4c781058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @delayed\n",
    "def experiment1(df_train, algorithm, fold, iteration, missingness, grid_search):\n",
    "    filename = f\"{output_dir}exp1_{algorithm}_{fold}_{iteration}_{missingness}.csv\"\n",
    "    \n",
    "    res = []\n",
    "    if not os.path.isfile(filename):\n",
    "        df_train_temp = df_train[df_train[\"fold\"]==fold].drop(\"fold\", axis=1).reset_index(drop=True)\n",
    "        parameters = [x for x in df_train_temp.columns if x.startswith(\"P_\")]\n",
    "\n",
    "        # determine indexes to remove\n",
    "        num_indexes = np.round(len(df_train_temp.index) / 100 * missingness).astype(int)\n",
    "        indexes_to_remove = np.random.randint(0, len(df_train_temp), num_indexes)\n",
    "    \n",
    "        for param in parameters:\n",
    "            x1, y1 = drop_values_from_one_param_by_index_and_scale(x_in=df_train_temp, parameter_in=param, indexes_in=indexes_to_remove)\n",
    "            for hyperparamerter_combination in grid_search:\n",
    "                rmse1, impute_time1 = run_imputer(x_in=x1, y_in=y1, predicting_in=param, hyperparamerter_dict_in=hyperparamerter_combination, imputer_name_in=algorithm)\n",
    "                res.append(pd.DataFrame({\"iteration\": [iteration],\n",
    "                                         \"missing_value_proportion\": [missingness],\n",
    "                                         \"predicting\": [param],\n",
    "                                         \"imputer\": [algorithm],\n",
    "                                         \"time\": [impute_time1],\n",
    "                                         \"rmse\": [rmse1],\n",
    "                                         \"hyperparameters\": [hyperparamerter_combination],\n",
    "                                         \"fold\": [fold]}))\n",
    "        pd.concat(res).to_csv(filename, index=False)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b39efa-2362-49d6-8b9f-dc6a2dad6472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_imputer 0 0 1\n",
      "mean_imputer 0 0 10\n",
      "mean_imputer 0 0 20\n",
      "mean_imputer 0 0 30\n",
      "mean_imputer 0 0 40\n",
      "mean_imputer 0 0 50\n",
      "mean_imputer 0 0 60\n",
      "mean_imputer 0 0 70\n",
      "mean_imputer 0 0 80\n",
      "mean_imputer 0 0 90\n",
      "mean_imputer 0 0 99\n",
      "mean_imputer 0 0 0.004239443784975411\n",
      "mean_imputer 0 1 1\n",
      "mean_imputer 0 1 10\n",
      "mean_imputer 0 1 20\n",
      "mean_imputer 0 1 30\n",
      "mean_imputer 0 1 40\n",
      "mean_imputer 0 1 50\n",
      "mean_imputer 0 1 60\n",
      "mean_imputer 0 1 70\n",
      "mean_imputer 0 1 80\n",
      "mean_imputer 0 1 90\n",
      "mean_imputer 0 1 99\n",
      "mean_imputer 0 1 0.004239443784975411\n",
      "mean_imputer 0 2 1\n",
      "mean_imputer 0 2 10\n",
      "mean_imputer 0 2 20\n",
      "mean_imputer 0 2 30\n",
      "mean_imputer 0 2 40\n",
      "mean_imputer 0 2 50\n",
      "mean_imputer 0 2 60\n",
      "mean_imputer 0 2 70\n",
      "mean_imputer 0 2 80\n",
      "mean_imputer 0 2 90\n",
      "mean_imputer 0 2 99\n",
      "mean_imputer 0 2 0.004239443784975411\n",
      "mean_imputer 0 3 1\n",
      "mean_imputer 0 3 10\n",
      "mean_imputer 0 3 20\n",
      "mean_imputer 0 3 30\n",
      "mean_imputer 0 3 40\n",
      "mean_imputer 0 3 50\n",
      "mean_imputer 0 3 60\n",
      "mean_imputer 0 3 70\n",
      "mean_imputer 0 3 80\n",
      "mean_imputer 0 3 90\n",
      "mean_imputer 0 3 99\n",
      "mean_imputer 0 3 0.004239443784975411\n",
      "mean_imputer 0 4 1\n",
      "mean_imputer 0 4 10\n",
      "mean_imputer 0 4 20\n",
      "mean_imputer 0 4 30\n",
      "mean_imputer 0 4 40\n",
      "mean_imputer 0 4 50\n",
      "mean_imputer 0 4 60\n",
      "mean_imputer 0 4 70\n",
      "mean_imputer 0 4 80\n",
      "mean_imputer 0 4 90\n",
      "mean_imputer 0 4 99\n",
      "mean_imputer 0 4 0.004239443784975411\n",
      "mean_imputer 0 5 1\n",
      "mean_imputer 0 5 10\n",
      "mean_imputer 0 5 20\n",
      "mean_imputer 0 5 30\n",
      "mean_imputer 0 5 40\n",
      "mean_imputer 0 5 50\n",
      "mean_imputer 0 5 60\n",
      "mean_imputer 0 5 70\n",
      "mean_imputer 0 5 80\n",
      "mean_imputer 0 5 90\n",
      "mean_imputer 0 5 99\n",
      "mean_imputer 0 5 0.004239443784975411\n",
      "mean_imputer 0 6 1\n",
      "mean_imputer 0 6 10\n",
      "mean_imputer 0 6 20\n",
      "mean_imputer 0 6 30\n",
      "mean_imputer 0 6 40\n",
      "mean_imputer 0 6 50\n",
      "mean_imputer 0 6 60\n",
      "mean_imputer 0 6 70\n",
      "mean_imputer 0 6 80\n",
      "mean_imputer 0 6 90\n",
      "mean_imputer 0 6 99\n",
      "mean_imputer 0 6 0.004239443784975411\n",
      "mean_imputer 0 7 1\n",
      "mean_imputer 0 7 10\n",
      "mean_imputer 0 7 20\n",
      "mean_imputer 0 7 30\n",
      "mean_imputer 0 7 40\n",
      "mean_imputer 0 7 50\n",
      "mean_imputer 0 7 60\n",
      "mean_imputer 0 7 70\n",
      "mean_imputer 0 7 80\n",
      "mean_imputer 0 7 90\n",
      "mean_imputer 0 7 99\n",
      "mean_imputer 0 7 0.004239443784975411\n",
      "mean_imputer 0 8 1\n",
      "mean_imputer 0 8 10\n",
      "mean_imputer 0 8 20\n",
      "mean_imputer 0 8 30\n",
      "mean_imputer 0 8 40\n",
      "mean_imputer 0 8 50\n",
      "mean_imputer 0 8 60\n",
      "mean_imputer 0 8 70\n",
      "mean_imputer 0 8 80\n",
      "mean_imputer 0 8 90\n",
      "mean_imputer 0 8 99\n",
      "mean_imputer 0 8 0.004239443784975411\n",
      "mean_imputer 0 9 1\n",
      "mean_imputer 0 9 10\n",
      "mean_imputer 0 9 20\n",
      "mean_imputer 0 9 30\n",
      "mean_imputer 0 9 40\n",
      "mean_imputer 0 9 50\n",
      "mean_imputer 0 9 60\n",
      "mean_imputer 0 9 70\n",
      "mean_imputer 0 9 80\n",
      "mean_imputer 0 9 90\n",
      "mean_imputer 0 9 99\n",
      "mean_imputer 0 9 0.004239443784975411\n",
      "mean_imputer 0 10 1\n",
      "mean_imputer 0 10 10\n",
      "mean_imputer 0 10 20\n",
      "mean_imputer 0 10 30\n",
      "mean_imputer 0 10 40\n",
      "mean_imputer 0 10 50\n",
      "mean_imputer 0 10 60\n",
      "mean_imputer 0 10 70\n",
      "mean_imputer 0 10 80\n",
      "mean_imputer 0 10 90\n",
      "mean_imputer 0 10 99\n",
      "mean_imputer 0 10 0.004239443784975411\n",
      "mean_imputer 0 11 1\n",
      "mean_imputer 0 11 10\n",
      "mean_imputer 0 11 20\n",
      "mean_imputer 0 11 30\n",
      "mean_imputer 0 11 40\n",
      "mean_imputer 0 11 50\n",
      "mean_imputer 0 11 60\n",
      "mean_imputer 0 11 70\n",
      "mean_imputer 0 11 80\n",
      "mean_imputer 0 11 90\n",
      "mean_imputer 0 11 99\n",
      "mean_imputer 0 11 0.004239443784975411\n",
      "mean_imputer 0 12 1\n",
      "mean_imputer 0 12 10\n",
      "mean_imputer 0 12 20\n",
      "mean_imputer 0 12 30\n",
      "mean_imputer 0 12 40\n",
      "mean_imputer 0 12 50\n",
      "mean_imputer 0 12 60\n",
      "mean_imputer 0 12 70\n",
      "mean_imputer 0 12 80\n",
      "mean_imputer 0 12 90\n",
      "mean_imputer 0 12 99\n",
      "mean_imputer 0 12 0.004239443784975411\n",
      "mean_imputer 0 13 1\n",
      "mean_imputer 0 13 10\n",
      "mean_imputer 0 13 20\n",
      "mean_imputer 0 13 30\n",
      "mean_imputer 0 13 40\n",
      "mean_imputer 0 13 50\n",
      "mean_imputer 0 13 60\n",
      "mean_imputer 0 13 70\n",
      "mean_imputer 0 13 80\n",
      "mean_imputer 0 13 90\n",
      "mean_imputer 0 13 99\n",
      "mean_imputer 0 13 0.004239443784975411\n",
      "mean_imputer 0 14 1\n",
      "mean_imputer 0 14 10\n",
      "mean_imputer 0 14 20\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res0 = []\n",
    "res1 = []\n",
    "algorithms=[\"mean_imputer\", \"knn_imputer\"]\n",
    "for algorithm in algorithms:\n",
    "    for fold in folds:        \n",
    "        for iteration in iterations:\n",
    "            for missingness in missing_value_proportions:\n",
    "                print(algorithm, fold, iteration, missingness)\n",
    "                res0.append(experiment0(df_train=df_train, algorithm=algorithm, fold=fold, iteration=iteration, missingness=missingness, grid_search=grid_search_dict[algorithm]))\n",
    "                res1.append(experiment1(df_train=df_train, algorithm=algorithm, fold=fold, iteration=iteration, missingness=missingness, grid_search=grid_search_dict[algorithm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e83bf-1ace-4aec-bbce-506818a52b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0[0].visualize()#engine=\"ipycytoscape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0280b-f906-4173-991d-cd5c86488011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with ProgressBar():\n",
    "    out0 = dask.compute(*res0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97fba6-361c-4c19-9bcb-91820e9a6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @todo store output\n",
    "pd.concat(out0).to_csv(f\"{output_dir}tuning_results_exp0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5ffad-8290-4bf7-bff5-718ef9245143",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with ProgressBar():\n",
    "    out1 = dask.compute(*res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5a2ee-4223-4005-ac97-a7673014ddae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# @todo store output\n",
    "pd.concat(out1).to_csv(f\"{output_dir}tuning_results_exp1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1fff30-7b54-4c28-822f-0f9a0191c494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5e43d-33f8-4899-baab-8acfad66f329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd0565-3d4c-488a-ae0f-3ba06ddd01b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dff2c9-8894-4cb5-9d13-1ad8e11d1c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834044c-3108-4c21-8b2b-7e63285918be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50636f-7df0-452b-9c59-79cf72a6d17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb25029-b376-4454-bf3c-6f83704753f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d34e83-2e5d-4bab-8a76-2a91501e1a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655cdfc-303a-4faa-8f89-abbc78798f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
