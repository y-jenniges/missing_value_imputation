{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bed00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a6ef6",
   "metadata": {},
   "source": [
    "# Compare MinMax and RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754be915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_unscale(file_path, scaler, exp_no=0):\n",
    "    xhat_unscaled = []\n",
    "    \n",
    "    for imputer_name in [\"gain_imputer\", \"missforest_imputer\", \"mean_imputer\", \"knn_imputer\"]:\n",
    "        print(f\"Load and scale for {imputer_name}\")\n",
    "        # load file\n",
    "        file_name = f\"testing_xhat_{imputer_name}_exp{exp_no}_grid.csv\"\n",
    "        temp_scaled = pd.read_csv(file_path + file_name)\n",
    "        temp_scaled[\"imputer\"] = temp_scaled[\"imputer\"].replace({\"missforest\": \"missforest_imputer\"})\n",
    "        \n",
    "        # undo scaling\n",
    "        temp_unscaled = pd.DataFrame(scaler.inverse_transform(temp_scaled[scaler.feature_names_in_]), columns=scaler.feature_names_in_)\n",
    "        \n",
    "        temp_unscaled = pd.concat([temp_unscaled.sort_values([\"LATITUDE\", \"LONGITUDE\", \"LEV_M\"]).reset_index(drop=True), \n",
    "                                   temp_scaled.sort_values([\"LATITUDE\", \"LONGITUDE\", \"LEV_M\"]).reset_index(drop=True)[\n",
    "                                       [\"experiment\", \"iteration\", \"missing_value_proportion\", \"imputer\"]]], axis=1)\n",
    "        xhat_unscaled.append(temp_unscaled)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return pd.concat(xhat_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58212f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(df_xhat, df_y, num_decimals=12, error_name=\"rmse\", \n",
    "                  parameters=['P_TEMPERATURE', 'P_SALINITY', 'P_OXYGEN', 'P_NITRATE','P_SILICATE', 'P_PHOSPHATE']):\n",
    "    df = df_xhat.copy()\n",
    "    df[[\"LATITUDE\", \"LONGITUDE\", \"LEV_M\"]] = round(df[[\"LATITUDE\", \"LONGITUDE\", \"LEV_M\"]], num_decimals)\n",
    "\n",
    "    df_merged = pd.merge(left=df, right=round(df_y, num_decimals), how=\"left\",\n",
    "                         on=[\"LATITUDE\", \"LONGITUDE\", \"LEV_M\"], suffixes=(\"_xhat\", \"_y\"))\n",
    "    \n",
    "    squaring = True if error_name == \"mse\" else False\n",
    "    \n",
    "    for p in parameters:\n",
    "        df_merged[f\"{error_name}_{p}\"] = df_merged.apply(lambda row : mean_squared_error([row[f\"{p}_y\"]], [row[f\"{p}_xhat\"]], squared=squaring), axis = 1)\n",
    "\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78fc0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scaler_comparison(df, error_name=\"rmse\", exp_no=0, save_as=None):\n",
    "    for param in [\"P_TEMPERATURE\", \"P_SALINITY\", \"P_OXYGEN\", \"P_NITRATE\", \"P_SILICATE\", \"P_PHOSPHATE\"]:\n",
    "        sns.lineplot(df, x=\"missing_value_proportion\", y=error_name + \"_\" + param + \"_minmax\", label=\"MinMaxScaler\")#, hue=\"imputer\")\n",
    "        sns.lineplot(df, x=\"missing_value_proportion\", y=error_name + \"_\" + param + \"_robust\", label=\"RobustScaler\")#, hue=\"imputer\")\n",
    "        \n",
    "        delta_error = df.copy()\n",
    "        delta_error[\"delta_error\"] = df[f\"rmse_{param}_robust\"] - df[f\"rmse_{param}_minmax\"]\n",
    "        sns.lineplot(delta_error, x=\"missing_value_proportion\", y=\"delta_error\", label=\"$RMSE_{minmax}-RMSE_{robust}$\")  # f\"$\\Delta {error_name.upper()}$\")\n",
    "        \n",
    "        plt.axhline(0, color=\"black\")\n",
    "        \n",
    "        plt.title(f\"Predicting {map_param_label[param].lower()} (exp{exp_no})\")\n",
    "        plt.xlabel(\"Missing value proportion [%]\")\n",
    "        plt.ylabel(f\"RMSE [{map_param_unit[param]}]\")\n",
    "        plt.legend()\n",
    "        if save_as:\n",
    "            plt.savefig(f\"output/scalerComparison_exp{exp_no}_{param}.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11e10cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yvjennig\\.conda\\envs\\clustering_real\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.1.3 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\yvjennig\\.conda\\envs\\clustering_real\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RobustScaler from version 1.1.3 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load scalers\n",
    "scaler_m = pickle.load(open(\"C:/Users/yvjennig/PycharmProjects/phd_repos/clustering/output/imputation/minmaxscaler/models/scaler.pickle\", \"rb\"))\n",
    "scaler_r = pickle.load(open(\"C:/Users/yvjennig/PycharmProjects/phd_repos/clustering/output/imputation/robustscaler/models/scaler.pickle\", \"rb\"))\n",
    "\n",
    "# load test file\n",
    "df_test_unscaled = pd.read_csv(\"C:/Users/yvjennig/PycharmProjects/phd_repos/clustering/data/test_table_0.8.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e942cb7",
   "metadata": {},
   "source": [
    "**Experiment 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2011d96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and scale for gain_imputer\n",
      "Load and scale for missforest_imputer\n",
      "Load and scale for mean_imputer\n",
      "Load and scale for knn_imputer\n",
      "\n",
      "Load and scale for gain_imputer\n",
      "Load and scale for missforest_imputer\n",
      "Load and scale for mean_imputer\n",
      "Load and scale for knn_imputer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load predictions and undo scaling\n",
    "path_exp0_minmax = f\"C:/Users/yvjennig/PycharmProjects/phd_repos/clustering/output/imputation/minmaxscaler/test_results/exp0/\"\n",
    "xhat0_unscaled_m = load_and_unscale(path_exp0_minmax, scaler_m, exp_no=0)\n",
    "\n",
    "path_exp0_robust = f\"C:/Users/yvjennig/PycharmProjects/phd_repos/clustering/output/imputation/robustscaler/test_results/exp0/\"\n",
    "xhat0_unscaled_r = load_and_unscale(path_exp0_robust, scaler_r, exp_no=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea300d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over iterations\n",
    "xhat0_unscaled_m_i = xhat0_unscaled_m.groupby([\"missing_value_proportion\", \"imputer\", \"experiment\", \"LATITUDE\", \"LONGITUDE\", \"LEV_M\"]).mean().reset_index()\n",
    "xhat0_unscaled_r_i = xhat0_unscaled_r.groupby([\"missing_value_proportion\", \"imputer\", \"experiment\", \"LATITUDE\", \"LONGITUDE\", \"LEV_M\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4478a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute error\n",
    "rmse0_unscaled_m = compute_error(xhat0_unscaled_m_i, df_test_unscaled, num_decimals=12, error_name=\"rmse\")\n",
    "rmse0_unscaled_r = compute_error(xhat0_unscaled_r_i, df_test_unscaled, num_decimals=12, error_name=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6020d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both dataframes\n",
    "df0 = pd.merge(left=rmse0_unscaled_m, right=rmse0_unscaled_r, how=\"left\", on=[\"imputer\", \"missing_value_proportion\", \n",
    "                                                                           \"LATITUDE\", \"LONGITUDE\", \"LEV_M\"], \n",
    "              suffixes=(\"_minmax\", \"_robust\")).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaler_comparison(df0, error_name=\"rmse\", exp_no=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fedd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average improvement with minmax\n",
    "for param in [\"P_TEMPERATURE\", \"P_SALINITY\", \"P_OXYGEN\", \"P_NITRATE\", \"P_SILICATE\", \"P_PHOSPHATE\"]:\n",
    "    print(param +  \":    \" + str((df0[f\"rmse_{param}_robust\"] - df0[f\"rmse_{param}_minmax\"]).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d82cea",
   "metadata": {},
   "source": [
    "**Experiment 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load predictions and undo scaling\n",
    "path_exp1_minmax = f\"C:/Users/yvjennig/PycharmProjects/phd_repos/clustering/output/imputation/minmaxscaler/test_results/exp1/\"\n",
    "xhat1_unscaled_m = load_and_unscale(path_exp1_minmax, scaler_m, exp_no=1)\n",
    "\n",
    "path_exp1_robust = f\"C:/Users/yvjennig/PycharmProjects/phd_repos/clustering/output/imputation/robustscaler/test_results/exp1/\"\n",
    "xhat1_unscaled_r = load_and_unscale(path_exp1_robust, scaler_r, exp_no=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over iterations\n",
    "xhat1_unscaled_m_i = xhat1_unscaled_m.groupby([\"missing_value_proportion\", \"imputer\", \"experiment\", \"LATITUDE\", \"LONGITUDE\", \"LEV_M\"]).mean().reset_index()\n",
    "xhat1_unscaled_r_i = xhat1_unscaled_r.groupby([\"missing_value_proportion\", \"imputer\", \"experiment\", \"LATITUDE\", \"LONGITUDE\", \"LEV_M\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bbd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute error\n",
    "rmse1_unscaled_m = compute_error(xhat1_unscaled_m_i, df_test_unscaled, 12, \"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse1_unscaled_r = compute_error(xhat1_unscaled_r_i, df_test_unscaled, 12, \"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both dataframes\n",
    "df1 = pd.merge(left=rmse1_unscaled_m, right=rmse1_unscaled_r, how=\"left\", on=[\"imputer\", \"missing_value_proportion\", \n",
    "                                                                           \"LATITUDE\", \"LONGITUDE\", \"LEV_M\"], \n",
    "              suffixes=(\"_minmax\", \"_robust\")).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e5767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"missing_value_proportion\"].replace({\"_P_NITRATE\": \"\"}, regex=True, inplace=True)\n",
    "df1[\"missing_value_proportion\"].replace({\"_P_SILICATE\": \"\"}, regex=True, inplace=True)\n",
    "df1[\"missing_value_proportion\"].replace({\"_P_PHOSPHATE\": \"\"}, regex=True, inplace=True)\n",
    "df1[\"missing_value_proportion\"].replace({\"_P_TEMPERATURE\": \"\"}, regex=True, inplace=True)\n",
    "df1[\"missing_value_proportion\"].replace({\"_P_SALINITY\": \"\"}, regex=True, inplace=True)\n",
    "df1[\"missing_value_proportion\"].replace({\"_P_OXYGEN\": \"\"}, regex=True, inplace=True)\n",
    "df1[\"missing_value_proportion\"] = df1[\"missing_value_proportion\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaler_comparison(df1, error_name=\"rmse\", exp_no=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average improvement with minmax\n",
    "for param in [\"P_TEMPERATURE\", \"P_SALINITY\", \"P_OXYGEN\", \"P_NITRATE\", \"P_SILICATE\", \"P_PHOSPHATE\"]:\n",
    "    print(param +  \":    \" + str((df1[f\"rmse_{param}_robust\"] - df1[f\"rmse_{param}_minmax\"]).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b61b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87167f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a4f1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
